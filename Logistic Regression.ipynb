{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db6f198e-867f-4e38-9456-88b2df52864f",
   "metadata": {},
   "source": [
    "\n",
    "### **Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**\n",
    "\n",
    "**Answer:**\n",
    "Logistic Regression is a statistical and machine learning technique used for **classification problems**, where the dependent variable is categorical (e.g., 0/1, Yes/No, Spam/Not Spam). Instead of predicting continuous outcomes like Linear Regression, Logistic Regression predicts the **probability** of a class label.\n",
    "\n",
    "The main differences are:\n",
    "\n",
    "1. **Output Nature**\n",
    "\n",
    "   * Linear Regression predicts continuous values (−∞ to +∞).\n",
    "   * Logistic Regression predicts probabilities (0 to 1).\n",
    "\n",
    "2. **Function Used**\n",
    "\n",
    "   * Linear Regression uses a straight-line equation.\n",
    "   * Logistic Regression applies the **sigmoid function** to map values between 0 and 1.\n",
    "\n",
    "3. **Application**\n",
    "\n",
    "   * Linear Regression → Continuous outcomes (e.g., predicting house prices).\n",
    "   * Logistic Regression → Categorical outcomes (e.g., predicting if an email is spam).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dcbb5-37a1-44ec-8d13-dde3670871af",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n",
    "\n",
    "**Answer:**\n",
    "The **sigmoid function** plays a crucial role in Logistic Regression by converting the output of a linear equation into a probability value between **0 and 1**.\n",
    "\n",
    "Mathematically, the sigmoid is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "where $z = β_0 + β_1x_1 + β_2x_2 + \\dots + β_nx_n$.\n",
    "\n",
    "**Role in Logistic Regression:**\n",
    "\n",
    "1. **Probability Mapping** – It transforms any real number (−∞ to +∞) into a probability score between 0 and 1.\n",
    "2. **Classification Decision** – A threshold (commonly 0.5) is applied:\n",
    "\n",
    "   * If probability ≥ 0.5 → Class 1\n",
    "   * If probability < 0.5 → Class 0\n",
    "3. **Non-linear Transformation** – Although the decision boundary is linear in feature space, the sigmoid ensures probabilities follow an **S-shaped curve**, making the model suitable for classification.\n",
    "\n",
    "**Example:**\n",
    "If the sigmoid output is **0.82**, the model predicts there is an **82% chance** the sample belongs to the positive class.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fec5c-20fd-4971-b3e3-5db9382eee20",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Question 3: What is Regularization in Logistic Regression and why is it needed?**\n",
    "\n",
    "**Answer:**\n",
    "**Regularization** is a technique used in Logistic Regression to **prevent overfitting** by adding a penalty term to the loss function. It controls the magnitude of model coefficients so that the model doesn’t become too complex and fit noise from the data.\n",
    "\n",
    "**Types of Regularization:**\n",
    "\n",
    "1. **L1 Regularization (Lasso):**\n",
    "\n",
    "   * Adds the absolute values of coefficients as a penalty.\n",
    "   * Some coefficients shrink to zero → helps in **feature selection**.\n",
    "\n",
    "2. **L2 Regularization (Ridge):**\n",
    "\n",
    "   * Adds the square of coefficients as a penalty.\n",
    "   * Shrinks coefficients smoothly → reduces **variance** and improves stability.\n",
    "\n",
    "**Why is it needed?**\n",
    "\n",
    "* Logistic Regression can overfit when:\n",
    "\n",
    "  * There are too many features.\n",
    "  * Features are highly correlated (multicollinearity).\n",
    "* Regularization ensures the model:\n",
    "\n",
    "  * Generalizes better to unseen data.\n",
    "  * Avoids extremely large coefficient values.\n",
    "  * Improves performance in real-world scenarios.\n",
    "\n",
    "**In practice:**\n",
    "Scikit-learn’s `LogisticRegression` uses **L2 regularization by default**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237be86f-b5b6-44a7-bd24-c9bb327547bb",
   "metadata": {},
   "source": [
    "\n",
    "### **Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n",
    "\n",
    "**Answer:**\n",
    "In classification tasks, accuracy alone may not be sufficient to judge model performance, especially in **imbalanced datasets**. Therefore, multiple evaluation metrics are used:\n",
    "\n",
    "1. **Accuracy**\n",
    "\n",
    "   * Formula: $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "   * Shows overall correctness of predictions.\n",
    "   * Limitation: Misleading in imbalanced datasets.\n",
    "\n",
    "2. **Precision**\n",
    "\n",
    "   * Formula: $\\frac{TP}{TP + FP}$\n",
    "   * Measures how many predicted positives are actually positive.\n",
    "   * Important when **false positives are costly** (e.g., spam filter).\n",
    "\n",
    "3. **Recall (Sensitivity / True Positive Rate)**\n",
    "\n",
    "   * Formula: $\\frac{TP}{TP + FN}$\n",
    "   * Measures how many actual positives were correctly identified.\n",
    "   * Important when **false negatives are costly** (e.g., disease detection).\n",
    "\n",
    "4. **F1-score**\n",
    "\n",
    "   * Harmonic mean of Precision and Recall.\n",
    "   * Useful when a balance between Precision and Recall is required.\n",
    "\n",
    "5. **ROC-AUC (Receiver Operating Characteristic – Area Under Curve)**\n",
    "\n",
    "   * Evaluates how well the model distinguishes between classes.\n",
    "   * Higher AUC → Better classifier.\n",
    "\n",
    "**Importance:**\n",
    "\n",
    "* Provides a **holistic view** of performance.\n",
    "* Helps select the **best model** based on business needs (e.g., prioritize Recall in healthcare, Precision in fraud detection).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81255313-4b0d-40da-b2b1-77ab5d4cde9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#**Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)**\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset from sklearn\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Convert to DataFrame (optional, for better view)\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce17991-8b58-4b83-8f82-e7d25b1a433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients:\n",
      " [[ 0.97796466  0.22675499 -0.36921764  0.02644054 -0.15485375 -0.22665079\n",
      "  -0.5186091  -0.27936438 -0.22284174 -0.03509306 -0.09377994  1.39092772\n",
      "  -0.17022173 -0.08877402 -0.02215899  0.05164999 -0.03656395 -0.03142397\n",
      "  -0.03290299  0.01227996  0.09595287 -0.51563694 -0.01698607 -0.01657517\n",
      "  -0.30594188 -0.74668265 -1.39907242 -0.50342187 -0.73505594 -0.09765041]]\n",
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients \n",
    "and accuracy. (Use Dataset from sklearn package)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression with L2 regularization (default)\n",
    "model = LogisticRegression(penalty='l2', C=1.0, max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Coefficients and accuracy\n",
    "print(\"Model Coefficients:\\n\", model.coef_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce68d750-ea6c-42de-9068-0fb20f9d0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raval\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the \n",
    "classification report. (Use Dataset from sklearn package)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset (Iris has 3 classes)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Logistic Regression with One-vs-Rest strategy\n",
    "model = LogisticRegression(multi_class='ovr', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dfbefd-c7fd-4204-8496-5ec031e0e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Cross-Validation Accuracy: 0.964835164835165\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters \n",
    "and validation accuracy. (Use Dataset from sklearn package)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']  # solver that supports both l1 and l2\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a38d3e-a251-419c-8a6b-bfa5daa69c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.956140350877193\n",
      "Accuracy with scaling: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and \n",
    "without scaling. (Use Dataset from sklearn package)\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression without scaling\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "acc_without_scaling = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with scaling\n",
    "model.fit(X_train_scaled, y_train)\n",
    "acc_with_scaling = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "\n",
    "print(\"Accuracy without scaling:\", acc_without_scaling)\n",
    "print(\"Accuracy with scaling:\", acc_with_scaling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ad3af-23f7-415d-8df0-0df0a2528076",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "To build a Logistic Regression model for this scenario, the steps would be:\n",
    "\n",
    "#### **1. Data Handling**\n",
    "\n",
    "* **Clean data**: Handle missing values, remove duplicates, and encode categorical variables (e.g., one-hot encoding).\n",
    "* **Feature engineering**: Create meaningful features such as purchase frequency, average spend, browsing behavior, etc.\n",
    "* **Remove noise**: Drop irrelevant variables that do not contribute to prediction.\n",
    "\n",
    "#### **2. Feature Scaling**\n",
    "\n",
    "* Standardize features using **StandardScaler** or **MinMaxScaler** to ensure fair contribution from all features.\n",
    "\n",
    "#### **3. Balancing Classes**\n",
    "\n",
    "Since only 5% of customers respond (positive class), the dataset is **highly imbalanced**. Options include:\n",
    "\n",
    "* **Oversampling minority class** (e.g., SMOTE – Synthetic Minority Oversampling Technique).\n",
    "* **Undersampling majority class** to balance the dataset.\n",
    "* **Class weights** in Logistic Regression (`class_weight='balanced'`) to penalize misclassification of minority class.\n",
    "\n",
    "#### **4. Hyperparameter Tuning**\n",
    "\n",
    "* Use **GridSearchCV** or **RandomizedSearchCV** to optimize parameters:\n",
    "\n",
    "  * `C` (regularization strength).\n",
    "  * `penalty` (L1 vs L2).\n",
    "  * Solver type.\n",
    "* Apply **cross-validation** for reliable results.\n",
    "\n",
    "#### **5. Evaluation Metrics**\n",
    "\n",
    "* Accuracy is misleading in imbalanced data. Instead, focus on:\n",
    "\n",
    "  * **Precision** → To ensure targeted customers are actually likely responders.\n",
    "  * **Recall** → To capture as many actual responders as possible.\n",
    "  * **F1-score** → Balance between Precision and Recall.\n",
    "  * **ROC-AUC** → Overall ability to distinguish responders vs non-responders.\n",
    "\n",
    "#### **6. Business Deployment**\n",
    "\n",
    "* Use the model to score new customers and rank them by probability of response.\n",
    "* Deploy in marketing pipeline for targeted campaigns.\n",
    "* Continuously monitor performance and retrain with new data to keep the model up-to-date.\n",
    "\n",
    "**In summary:**\n",
    "\n",
    "* Handle imbalance carefully.\n",
    "* Scale features before training.\n",
    "* Use hyperparameter tuning for optimization.\n",
    "* Evaluate using Precision, Recall, F1-score, and ROC-AUC instead of just accuracy.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84da62-d930-4a9a-9066-043b0f3c9653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
